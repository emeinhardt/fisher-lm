{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eric Meinhardt / emeinhardt@ucsd.edu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:06:24.150599Z",
     "start_time": "2019-04-25T22:06:24.147440Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:10:27.621734Z",
     "start_time": "2019-04-26T01:10:27.619623Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:12:15.097633Z",
     "start_time": "2019-04-25T22:12:15.095648Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:25:51.092655Z",
     "start_time": "2019-04-25T22:25:51.086619Z"
    }
   },
   "outputs": [],
   "source": [
    "def readStringList(fp):\n",
    "    lines = []\n",
    "    with open(fp, 'r') as file:\n",
    "        for line in file:\n",
    "            lines.append(line.rstrip())\n",
    "    return lines\n",
    "\n",
    "def writeStringList(fp, strings):\n",
    "    with open(fp, 'w') as file:\n",
    "        strings_w_linebreaks = list(map(lambda l: l + \"\\n\", strings))\n",
    "        file.writelines(strings_w_linebreaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:36:22.689799Z",
     "start_time": "2019-04-25T22:36:22.687425Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T23:09:39.019171Z",
     "start_time": "2019-04-25T23:09:39.016989Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:28:52.590491Z",
     "start_time": "2019-04-25T22:28:52.549782Z"
    }
   },
   "outputs": [],
   "source": [
    "import kenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "# from itertools import chain\n",
    "# import re\n",
    "# from more_itertools import replace\n",
    "# from funcy import compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T00:55:05.075774Z",
     "start_time": "2019-04-26T00:55:04.828428Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "J = 20\n",
    "BACKEND = 'multiprocessing'\n",
    "# BACKEND = 'loky'\n",
    "V = 10\n",
    "PREFER = 'processes'\n",
    "# PREFER = 'threads'\n",
    "\n",
    "def par(gen_expr):\n",
    "    return Parallel(n_jobs=J, backend=BACKEND, verbose=V, prefer=PREFER)(gen_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:08:51.650326Z",
     "start_time": "2019-04-25T22:08:51.647731Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_dir = '/mnt/cube/home/AD/emeinhar/fisher-lm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview-&amp;-Requirements\" data-toc-modified-id=\"Overview-&amp;-Requirements-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview &amp; Requirements</a></span></li><li><span><a href=\"#Loading-data\" data-toc-modified-id=\"Loading-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Loading data</a></span></li><li><span><a href=\"#Splitting-the-corpus-into-training-and-test-sets\" data-toc-modified-id=\"Splitting-the-corpus-into-training-and-test-sets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Splitting the corpus into training and test sets</a></span></li><li><span><a href=\"#Build-preliminary-files-for-each-language-model-of-interest\" data-toc-modified-id=\"Build-preliminary-files-for-each-language-model-of-interest-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build preliminary files for each language model of interest</a></span></li><li><span><a href=\"#Creating-and-querying-a-model-using-the-kenlm-python-package\" data-toc-modified-id=\"Creating-and-querying-a-model-using-the-kenlm-python-package-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Creating and querying a model using the <code>kenlm</code> python package</a></span></li><li><span><a href=\"#Calculate-perplexity-of-the-test-set-for-each-model\" data-toc-modified-id=\"Calculate-perplexity-of-the-test-set-for-each-model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Calculate perplexity of the test set for each model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview & Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:10:22.776078Z",
     "start_time": "2019-04-25T22:10:22.773700Z"
    }
   },
   "outputs": [],
   "source": [
    "main_corpus_fn = 'fisher_utterances_main.txt'\n",
    "bbn_corpus_fn = 'fisher_utterances_bbn.txt'\n",
    "\n",
    "my_corpus_fn = main_corpus_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:25:08.166024Z",
     "start_time": "2019-04-25T22:25:07.853613Z"
    }
   },
   "outputs": [],
   "source": [
    "utterances = readStringList(my_corpus_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:25:10.296191Z",
     "start_time": "2019-04-25T22:25:10.292942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077813"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the corpus into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:25:12.895596Z",
     "start_time": "2019-04-25T22:25:12.891452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107781"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_proportion = 0.10\n",
    "\n",
    "exact_num_test_utterances = round(test_proportion * len(utterances))\n",
    "exact_num_test_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:25:13.220401Z",
     "start_time": "2019-04-25T22:25:13.215147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i mean no money is very important definitely and a million dollars is a dream come true for me i mean'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"and they're not as strict either\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances[0]\n",
    "utterances[23124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:25:14.674357Z",
     "start_time": "2019-04-25T22:25:13.819170Z"
    }
   },
   "outputs": [],
   "source": [
    "random.shuffle(utterances) #stateful, in-place shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:25:14.679551Z",
     "start_time": "2019-04-25T22:25:14.676117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and i think it does make a big difference and i think with today's society and economy and everything that they're going to have to have it\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"but mhm but i mean if it doesn't hurt the employer that <rem> well\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances[0]\n",
    "utterances[23124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:25:15.307261Z",
     "start_time": "2019-04-25T22:25:15.203048Z"
    }
   },
   "outputs": [],
   "source": [
    "test_utterances = utterances[:exact_num_test_utterances]\n",
    "training_utterances = utterances[exact_num_test_utterances:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility, we want to export these..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T23:16:23.453007Z",
     "start_time": "2019-04-25T23:16:23.448081Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set_prefix = 'fisher_test_utterances'\n",
    "training_set_prefix = 'fisher_training_utterances'\n",
    "\n",
    "test_set_fn = test_set_prefix + '.txt'\n",
    "training_set_fn = training_set_prefix + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:26:07.606300Z",
     "start_time": "2019-04-25T22:26:06.603588Z"
    }
   },
   "outputs": [],
   "source": [
    "writeStringList(test_set_fn, test_utterances)\n",
    "writeStringList(training_set_fn, training_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:26:38.412718Z",
     "start_time": "2019-04-25T22:26:38.296212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\tand i think it does make a big difference and i think with today's society and economy and everything that they're going to have to have it\r\n",
      "     2\tright\r\n",
      "     3\tcourse when things go wrong they can really go wrong you know\r\n",
      "     4\tso and why did they move from sundays i do not know\r\n",
      "     5\tmhm\r\n",
      "     6\tand the seasons changing and getting ill during season changes or something\r\n",
      "     7\tand it just got so bad that i couldn't even work\r\n",
      "     8\tso it'll make it\r\n",
      "     9\tconfide into you can maybe live your life with something like that you know something which is long lasting someone you can\r\n",
      "    10\tbut they're incorrect\r\n",
      "cat: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "%cat -n /mnt/cube/home/AD/emeinhar/fisher-lm/fisher_test_utterances.txt | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:26:52.539479Z",
     "start_time": "2019-04-25T22:26:52.420940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\tyeah well it's in cattle\r\n",
      "     2\tno i don't think so i mean that ah if if they planned that then they would have linked it directly to iraq right why go in afghanistan and waste all the all the time\r\n",
      "     3\tyeah i\r\n",
      "     4\twe we we've been married fifty six years\r\n",
      "     5\tmhm\r\n",
      "     6\tbuild their government how they want it not\r\n",
      "     7\ti mean i don't it you know i'm not a real big sports fan but i just you know i don't really watch it that much but i mean i know that kids used to enjoy it and they'd talk about the great games and stuff but it doesn't seem like they know what they're talking about any more\r\n",
      "     8\tsome sort of greens you know um\r\n",
      "     9\tmhm\r\n",
      "    10\ti mean unless you have a horrible like drug addiction\r\n",
      "cat: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "%cat -n /mnt/cube/home/AD/emeinhar/fisher-lm/fisher_training_utterances.txt | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build preliminary files for each language model of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as we are concerned, there are two parameter choices for the language model:\n",
    " - the choice of $n$ (as in $n$-gram)\n",
    " - the minimum token count threshold $p$ tokens must have before they are pruned\n",
    "\n",
    "Choices:\n",
    " - $n \\in \\{1, 2, 3, 4, 5\\}$\n",
    " - $p \\in \\{0, 5, 10\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:36:48.270077Z",
     "start_time": "2019-04-25T22:36:48.267577Z"
    }
   },
   "outputs": [],
   "source": [
    "N = (1,2,3,4,5)\n",
    "P = (0,5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two shell commands below \n",
    " - build a unigram model (from the complete set of LDC transcriptions) with no pruning.\n",
    " - build a binary memory map version of that same `.arpa` file for faster queries.\n",
    " \n",
    "```\n",
    "/home/AD/emeinhar/GitHub/kenlm/build/bin/lmplz -o 1 --text fisher_training_utterances.txt --arpa fisher_training_utterances_1gram.arpa\n",
    "```\n",
    "\n",
    "```\n",
    "/home/AD/emeinhar/GitHub/kenlm/build/bin/build_binary fisher_training_utterances_1gram.arpa fisher_training_utterances_1gram.mmap\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `subprocess` module to build and execute as many of these shell calls as we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:36:58.044919Z",
     "start_time": "2019-04-25T22:36:58.042064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cube/home/AD/emeinhar/fisher-lm'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:40:58.349775Z",
     "start_time": "2019-04-25T22:40:58.344310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/AD/emeinhar/GitHub/kenlm/build/bin/lmplz'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/home/AD/emeinhar/GitHub/kenlm/build/bin/build_binary'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kenlm_path = '/home/AD/emeinhar/GitHub/kenlm/'\n",
    "lmplz_path = os.path.join(kenlm_path, 'build/bin/lmplz')\n",
    "lmplz_path\n",
    "lmplz = lmplz_path\n",
    "\n",
    "build_binary_path = os.path.join(kenlm_path, 'build/bin/build_binary')\n",
    "build_binary_path\n",
    "build_binary = build_binary_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T23:44:53.973858Z",
     "start_time": "2019-04-25T23:44:53.968037Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(n, p, training_set_prefix):\n",
    "    assert n in N\n",
    "    assert p in P\n",
    "    assert p == 0, 'p other than 0 not supported yet'\n",
    "    \n",
    "    print(\"Building .arpa and .memmap files for n='{0}', p='{1}', training_set_prefix='{2}'\".format(n, p, training_set_prefix))\n",
    "    print('\\n')\n",
    "    \n",
    "    training_set_fn = training_set_prefix + '.txt'\n",
    "    arpa_fn = training_set_prefix + '_{0}gram'.format(n) + '.arpa'\n",
    "    mmap_fn = training_set_prefix + '_{0}gram'.format(n) + '.mmap'\n",
    "    \n",
    "    fns = {'training_set':training_set_fn,\n",
    "           'arpa':arpa_fn,\n",
    "           'mmap':mmap_fn}\n",
    "    \n",
    "    build_arpa_file = [lmplz, '-o', str(n), \n",
    "                              '--text', training_set_fn,\n",
    "                              '--arpa', arpa_fn]\n",
    "    build_mmap_file = [build_binary, arpa_fn, \n",
    "                                     mmap_fn]\n",
    "\n",
    "#     subprocess.run(build_arpa_file)\n",
    "#     subprocess.run(build_mmap_file)\n",
    "#     arpa_build_out = subprocess.run(build_arpa_file, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "#     print(arpa_build_out)\n",
    "    \n",
    "#     binary_build_out = subprocess.run(build_mmap_file, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "#     print(binary_build_out)\n",
    "    \n",
    "    build_arpa_file_cmd = ' '.join(build_arpa_file)\n",
    "    build_mmap_file_cmd = ' '.join(build_mmap_file)\n",
    "    \n",
    "#     os.system(build_arpa_file_cmd)\n",
    "#     os.system(build_mmap_file_cmd)\n",
    "#     arpa_build_out = subprocess.run(build_arpa_file_cmd, shell=True, stdout=subprocess.PIPE, \n",
    "#                         universal_newlines=True)\n",
    "    arpa_build_out = subprocess.getoutput(build_arpa_file_cmd)\n",
    "    print(arpa_build_out)\n",
    "    \n",
    "    print(' ')\n",
    "    if n == 1:\n",
    "        print('build_binary requires n > 1. Skipping.\\n')\n",
    "        fns['mmap'] = None\n",
    "    if n != 1:\n",
    "    #     binary_build_out = subprocess.run(build_mmap_file_cmd, shell=True, stdout=subprocess.PIPE, \n",
    "    #                         universal_newlines=True)\n",
    "        binary_build_out = subprocess.getoutput(build_mmap_file_cmd)\n",
    "        print(binary_build_out)\n",
    "        print('\\n')\n",
    "    \n",
    "    print('Done.')\n",
    "    print('\\n')\n",
    "    return fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T23:44:54.838929Z",
     "start_time": "2019-04-25T23:44:54.834369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 0, 'fisher_training_utterances'),\n",
       " (2, 0, 'fisher_training_utterances'),\n",
       " (3, 0, 'fisher_training_utterances'),\n",
       " (4, 0, 'fisher_training_utterances'),\n",
       " (5, 0, 'fisher_training_utterances'))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_combinations = tuple(product(N, \n",
    "                                       {0}, #P,\n",
    "                                       {training_set_prefix},\n",
    "                                      ))\n",
    "parameter_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T23:46:55.107483Z",
     "start_time": "2019-04-25T23:45:27.385151Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building .arpa and .memmap files for n='1', p='0', training_set_prefix='fisher_training_utterances'\n",
      "\n",
      "\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /mnt/cube/home/AD/emeinhar/fisher-lm/fisher_training_utterances.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 9666028 types 42524\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:510288\n",
      "Statistics:\n",
      "1 42524 D1=0.564287 D2=1.00862 D3+=1.42603\n",
      "Memory estimate for binary LM:\n",
      "type      kB\n",
      "probing 1827 assuming -p 1.5\n",
      "probing 1993 assuming -r models -p 1.5\n",
      "trie    1240 without quantization\n",
      "trie    1120 assuming -q 8 -b 8 quantization \n",
      "trie    1240 assuming -a 22 array pointer compression\n",
      "trie    1120 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:510288\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:510288\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:105760580 kB\tVmRSS:7328 kB\tRSSMax:35211836 kB\tuser:2.68331\tsys:7.101\tCPU:9.78432\treal:9.8409\n",
      " \n",
      "build_binary requires n > 1. Skipping.\n",
      "\n",
      "Done.\n",
      "\n",
      "\n",
      "Building .arpa and .memmap files for n='2', p='0', training_set_prefix='fisher_training_utterances'\n",
      "\n",
      "\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /mnt/cube/home/AD/emeinhar/fisher-lm/fisher_training_utterances.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 9666028 types 42524\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:510288 2:108102172672\n",
      "Statistics:\n",
      "1 42524 D1=0.571273 D2=1.00223 D3+=1.4377\n",
      "2 862173 D1=0.688768 D2=1.07046 D3+=1.38626\n",
      "Memory estimate for binary LM:\n",
      "type       kB\n",
      "probing 16235 assuming -p 1.5\n",
      "probing 16401 assuming -r models -p 1.5\n",
      "trie     5943 without quantization\n",
      "trie     3523 assuming -q 8 -b 8 quantization \n",
      "trie     5943 assuming -a 22 array pointer compression\n",
      "trie     3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:510288 2:13794768\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:510288 2:13794768\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:105760576 kB\tVmRSS:21164 kB\tRSSMax:28827520 kB\tuser:3.87024\tsys:5.50149\tCPU:9.37174\treal:9.54843\n",
      " \n",
      "Reading fisher_training_utterances_2gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "\n",
      "Building .arpa and .memmap files for n='3', p='0', training_set_prefix='fisher_training_utterances'\n",
      "\n",
      "\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /mnt/cube/home/AD/emeinhar/fisher-lm/fisher_training_utterances.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 9666028 types 42524\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:510288 2:37600755712 3:70501416960\n",
      "Statistics:\n",
      "1 42524 D1=0.571273 D2=1.00223 D3+=1.4377\n",
      "2 862173 D1=0.701804 D2=1.07756 D3+=1.4083\n",
      "3 3259561 D1=0.783491 D2=1.09606 D3+=1.32202\n",
      "Memory estimate for binary LM:\n",
      "type    MB\n",
      "probing 76 assuming -p 1.5\n",
      "probing 81 assuming -r models -p 1.5\n",
      "trie    29 without quantization\n",
      "trie    15 assuming -q 8 -b 8 quantization \n",
      "trie    28 assuming -a 22 array pointer compression\n",
      "trie    14 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:510288 2:13794768 3:65191220\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:510288 2:13794768 3:65191220\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:105760580 kB\tVmRSS:21552 kB\tRSSMax:24450012 kB\tuser:6.20354\tsys:5.52091\tCPU:11.7245\treal:12.465\n",
      " \n",
      "Reading fisher_training_utterances_3gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "\n",
      "Building .arpa and .memmap files for n='4', p='0', training_set_prefix='fisher_training_utterances'\n",
      "\n",
      "\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /mnt/cube/home/AD/emeinhar/fisher-lm/fisher_training_utterances.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 9666028 types 42524\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:510288 2:18400368640 3:34500694016 4:55201107968\n",
      "Statistics:\n",
      "1 42524 D1=0.571273 D2=1.00223 D3+=1.4377\n",
      "2 862173 D1=0.701804 D2=1.07756 D3+=1.4083\n",
      "3 3259561 D1=0.797247 D2=1.11664 D3+=1.36535\n",
      "4 5763906 D1=0.867327 D2=1.1644 D3+=1.32236\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 194 assuming -p 1.5\n",
      "probing 218 assuming -r models -p 1.5\n",
      "trie     83 without quantization\n",
      "trie     44 assuming -q 8 -b 8 quantization \n",
      "trie     76 assuming -a 22 array pointer compression\n",
      "trie     37 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:510288 2:13794768 3:65191220 4:138333744\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:510288 2:13794768 3:65191220 4:138333744\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:105760572 kB\tVmRSS:21420 kB\tRSSMax:21276064 kB\tuser:9.20836\tsys:5.65285\tCPU:14.8612\treal:16.3064\n",
      " \n",
      "Reading fisher_training_utterances_4gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "\n",
      "Building .arpa and .memmap files for n='5', p='0', training_set_prefix='fisher_training_utterances'\n",
      "\n",
      "\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /mnt/cube/home/AD/emeinhar/fisher-lm/fisher_training_utterances.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 9666028 types 42524\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:510288 2:10546552832 3:19774787584 4:31639658496 5:46141173760\n",
      "Statistics:\n",
      "1 42524 D1=0.571273 D2=1.00223 D3+=1.4377\n",
      "2 862173 D1=0.701804 D2=1.07756 D3+=1.4083\n",
      "3 3259561 D1=0.797247 D2=1.11664 D3+=1.36535\n",
      "4 5763906 D1=0.880362 D2=1.19836 D3+=1.3941\n",
      "5 6932392 D1=0.932211 D2=1.2604 D3+=1.35533\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 346 assuming -p 1.5\n",
      "probing 403 assuming -r models -p 1.5\n",
      "trie    159 without quantization\n",
      "trie     85 assuming -q 8 -b 8 quantization \n",
      "trie    141 assuming -a 22 array pointer compression\n",
      "trie     67 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:510288 2:13794768 3:65191220 4:138333744 5:194106976\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:510288 2:13794768 3:65191220 4:138333744 5:194106976\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:105767780 kB\tVmRSS:21488 kB\tRSSMax:18854656 kB\tuser:13.12\tsys:6.21091\tCPU:19.3309\treal:21.2051\n",
      " \n",
      "Reading fisher_training_utterances_5gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_files = []\n",
    "for n, p, prefix in parameter_combinations:\n",
    "    output_files.append(build_model(n, p, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T23:46:55.112531Z",
     "start_time": "2019-04-25T23:46:55.109348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_1gram.arpa',\n",
       "  'mmap': None},\n",
       " {'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_2gram.arpa',\n",
       "  'mmap': 'fisher_training_utterances_2gram.mmap'},\n",
       " {'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_3gram.arpa',\n",
       "  'mmap': 'fisher_training_utterances_3gram.mmap'},\n",
       " {'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_4gram.arpa',\n",
       "  'mmap': 'fisher_training_utterances_4gram.mmap'},\n",
       " {'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_5gram.arpa',\n",
       "  'mmap': 'fisher_training_utterances_5gram.mmap'}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T23:54:12.793877Z",
     "start_time": "2019-04-25T23:54:12.790097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_1gram.arpa',\n",
       "   'mmap': None}),\n",
       " ((2, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_2gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_2gram.mmap'}),\n",
       " ((3, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_3gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_3gram.mmap'}),\n",
       " ((4, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_4gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_4gram.mmap'}),\n",
       " ((5, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_5gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_5gram.mmap'}))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_and_models = tuple(zip(parameter_combinations,\n",
    "                                  output_files))\n",
    "parameters_and_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and querying a model using the `kenlm` python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T00:20:27.761793Z",
     "start_time": "2019-04-26T00:20:27.759498Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(arpa_or_memmap_fp):\n",
    "    return kenlm.LanguageModel(arpa_or_memmap_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T00:13:22.658213Z",
     "start_time": "2019-04-26T00:13:22.656050Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import log2, log10, pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T00:58:25.982346Z",
     "start_time": "2019-04-26T00:58:25.970640Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_utterance_score_and_perplexity_functions(model, base=None, parallelize=False):\n",
    "    if base is None:\n",
    "        base = 10\n",
    "    assert base == 10 or base == 2\n",
    "\n",
    "    if base == 10:\n",
    "        changeOfBase = lambda log10p: log10p\n",
    "    else:\n",
    "        changeOfBase = lambda log10p: log2(pow(10, log10p))\n",
    "    \n",
    "    def score(utterance):\n",
    "        return changeOfBase( model.score(utterance) )\n",
    "    \n",
    "    def perplexity_u(utterance):\n",
    "        score = changeOfBase( model.score(utterance) )\n",
    "        n = len(utterance.split(' ')) + 1\n",
    "#         print('base = {0}'.format(base))\n",
    "#         print('{0} vs. {1}'.format(2 ** (-1.0 * score / n), pow(base, -1.0 * score / n)))\n",
    "        perp = pow(base, -1.0 * score / n)\n",
    "        return perp\n",
    "    \n",
    "    def perplexity_c(utterances):\n",
    "        N = sum(map(lambda utt: len(utt.split(' ')) + 1,\n",
    "                    utterances))\n",
    "        \n",
    "        if not parallelize:\n",
    "            sentence_scores = (score(u) for u in utterances)\n",
    "            sum_of_scores = sum(sentence_scores)\n",
    "        else:\n",
    "            sentence_scores = par((delayed(score)(u) for u in utterances))\n",
    "            sum_of_scores = sum(sentence_scores)\n",
    "        \n",
    "        perp = pow(base, -1.0 * (1.0 / N) * sum_of_scores)\n",
    "        return perp\n",
    "    \n",
    "#     return {'score':score, \n",
    "#             'perplexity':perplexity}\n",
    "    return score, perplexity_u, perplexity_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:24:41.982990Z",
     "start_time": "2019-04-26T01:24:41.980119Z"
    }
   },
   "outputs": [],
   "source": [
    "def changeOfBase(log10p):\n",
    "    return log2(pow(10, log10p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:14.244583Z",
     "start_time": "2019-04-26T01:27:14.239094Z"
    }
   },
   "outputs": [],
   "source": [
    "def perplexity_corpus(utterances, model, base=None, parallelize=False):\n",
    "    if base is None:\n",
    "        base = 10\n",
    "    assert base == 10 or base == 2\n",
    "    \n",
    "    if base == 10:\n",
    "        changeOfBase = lambda log10p: log10p\n",
    "#     else:\n",
    "#         changeOfBase = lambda log10p: log2(pow(10, log10p))\n",
    "#     score = lambda utt: changeOfBase( model.score(utt) )\n",
    "    \n",
    "    N = sum(map(lambda utt: len(utt.split(' ')) + 1,\n",
    "                    utterances))\n",
    "    if not parallelize:\n",
    "        sentence_scores = (changeOfBase(model.score(u)) for u in utterances)\n",
    "        sum_of_scores = sum(sentence_scores)\n",
    "    else:\n",
    "        if base == 10:\n",
    "            sentence_scores = par((delayed(model.score)(u) for u in utterances))\n",
    "            sum_of_scores = sum(sentence_scores)\n",
    "        else:\n",
    "            sentence_scores = par((delayed(model.score)(u) for u in utterances))\n",
    "            sentence_scores_base2 = (changeOfBase(s) for s in sentence_scores)\n",
    "            sum_of_scores = sum(sentence_scores)\n",
    "\n",
    "    perp = pow(base, -1.0 * (1.0 / N) * sum_of_scores)\n",
    "    return perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:16.154931Z",
     "start_time": "2019-04-26T01:27:16.150816Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram = make_model('fisher_training_utterances_2gram.mmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram.score(\"this is a sentence\")\n",
    "bigram.score(\"this is a sentence\", eos = True)\n",
    "bigram.score(\"this is a sentence </s>\", eos=False)\n",
    "bigram.score(\"this is a sentence </s>\")\n",
    "tuple(bigram.full_scores(\"this is a sentence\"))\n",
    "sum(map(lambda triple: triple[0],\n",
    "        tuple(bigram.full_scores(\"this is a sentence\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:16.675816Z",
     "start_time": "2019-04-26T01:27:16.671839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"has anyone ever told you\"\n",
    "n = len(test_sentence.split(' ')) + 1\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:17.073589Z",
     "start_time": "2019-04-26T01:27:17.069829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.384958267211914"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = bigram.score(test_sentence)\n",
    "s # = log_10( p(test_sentence) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:17.377500Z",
     "start_time": "2019-04-26T01:27:17.373052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366.5723563463184"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "366.5723563463184"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram.perplexity(test_sentence)\n",
    "10.0 ** (-1.0 * s / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:17.671166Z",
     "start_time": "2019-04-26T01:27:17.668800Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_score, bigram_perplexity_utt, bigram_perplexity_corpus = make_utterance_score_and_perplexity_functions(bigram, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:18.047254Z",
     "start_time": "2019-04-26T01:27:18.043076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.384958267211914"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "366.5723563463184"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "366.572356346318"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_score(test_sentence)\n",
    "bigram_perplexity_utt(test_sentence)\n",
    "bigram_perplexity_corpus([test_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:18.525508Z",
     "start_time": "2019-04-26T01:27:18.522336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896.605570590842"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [test_sentence, 'call me ishmael']\n",
    "bigram_perplexity_corpus(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate perplexity of the test set for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:20.070315Z",
     "start_time": "2019-04-26T01:27:20.066781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_1gram.arpa',\n",
       "   'mmap': None}),\n",
       " ((2, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_2gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_2gram.mmap'}),\n",
       " ((3, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_3gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_3gram.mmap'}),\n",
       " ((4, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_4gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_4gram.mmap'}),\n",
       " ((5, 0, 'fisher_training_utterances'),\n",
       "  {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_5gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_5gram.mmap'}))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters_and_models = tuple(zip(parameter_combinations,\n",
    "#                                   output_files))\n",
    "parameters_and_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:20.415626Z",
     "start_time": "2019-04-26T01:27:20.411336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_2gram.arpa',\n",
       "  'mmap': 'fisher_training_utterances_2gram.mmap'},\n",
       " {'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_3gram.arpa',\n",
       "  'mmap': 'fisher_training_utterances_3gram.mmap'},\n",
       " {'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_4gram.arpa',\n",
       "  'mmap': 'fisher_training_utterances_4gram.mmap'},\n",
       " {'training_set': 'fisher_training_utterances.txt',\n",
       "  'arpa': 'fisher_training_utterances_5gram.arpa',\n",
       "  'mmap': 'fisher_training_utterances_5gram.mmap'}]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_files[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:21.408375Z",
     "start_time": "2019-04-26T01:27:21.368551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models = tuple(map(make_model,\n",
    "#                    (output_files[0]['arpa'],) + tuple(map(lambda output_file_dict:output_file_dict['mmap'],\n",
    "#                                                           output_files[1:]))))\n",
    "models = tuple(map(make_model,\n",
    "                   tuple(map(lambda output_file_dict:output_file_dict['mmap'],\n",
    "                             output_files[1:]))))\n",
    "\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:21.435850Z",
     "start_time": "2019-04-26T01:27:21.410137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'parameters': (1, 0, 'fisher_training_utterances'),\n",
       "  'files': {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_1gram.arpa',\n",
       "   'mmap': None},\n",
       "  'model': None},\n",
       " {'parameters': (2, 0, 'fisher_training_utterances'),\n",
       "  'files': {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_2gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_2gram.mmap'},\n",
       "  'model': <Model from b'fisher_training_utterances_2gram.mmap'>},\n",
       " {'parameters': (3, 0, 'fisher_training_utterances'),\n",
       "  'files': {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_3gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_3gram.mmap'},\n",
       "  'model': <Model from b'fisher_training_utterances_3gram.mmap'>},\n",
       " {'parameters': (4, 0, 'fisher_training_utterances'),\n",
       "  'files': {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_4gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_4gram.mmap'},\n",
       "  'model': <Model from b'fisher_training_utterances_4gram.mmap'>},\n",
       " {'parameters': (5, 0, 'fisher_training_utterances'),\n",
       "  'files': {'training_set': 'fisher_training_utterances.txt',\n",
       "   'arpa': 'fisher_training_utterances_5gram.arpa',\n",
       "   'mmap': 'fisher_training_utterances_5gram.mmap'},\n",
       "  'model': <Model from b'fisher_training_utterances_5gram.mmap'>})"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_collection = tuple(zip(parameter_combinations,\n",
    "                             output_files,\n",
    "                             (None,) + models))\n",
    "add_labels = lambda threeTuple: {'parameters':threeTuple[0],\n",
    "                                 'files':threeTuple[1],\n",
    "                                 'model':threeTuple[2]}\n",
    "model_collection = tuple(map(add_labels,\n",
    "                             model_collection))\n",
    "model_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:21.946554Z",
     "start_time": "2019-04-26T01:27:21.941195Z"
    }
   },
   "outputs": [],
   "source": [
    "def testModel(model_dict, base, parallelize, corpus):\n",
    "    d = model_dict\n",
    "    params = d['parameters']\n",
    "    n = params[0]\n",
    "    p = params[1]\n",
    "    print('Testing model w/ params n = {0} and p = {1}'.format(n, p))\n",
    "    model = d['model']\n",
    "    \n",
    "#     _, _, perplexity_corpus = make_utterance_score_and_perplexity_functions(model, base, parallelize)\n",
    "    \n",
    "    perp = perplexity_corpus(corpus, model, base, parallelize)\n",
    "    return perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:23.129983Z",
     "start_time": "2019-04-26T01:27:23.125968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107781"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_set = readStringList\n",
    "len(test_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:27:34.983129Z",
     "start_time": "2019-04-26T01:27:34.686121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model w/ params n = 2 and p = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89.7021667016168"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bigram model, base 10 perplexity, parallelize\n",
    "testModel(model_collection[1], 10, False, test_utterances) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T01:28:41.076827Z",
     "start_time": "2019-04-26T01:28:39.416234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model w/ params n = 2 and p = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89.7021667016168"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model w/ params n = 3 and p = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.96781399496341"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model w/ params n = 4 and p = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.84960527446214"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model w/ params n = 5 and p = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.76068548524647"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in model_collection[1:]:\n",
    "    testModel(m, 10, False, test_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: try pruning parameters, try an off-the-shelf set of .arpa weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
